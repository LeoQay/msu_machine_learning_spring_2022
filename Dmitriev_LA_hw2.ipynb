{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №2: Линейные модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 25 апреля 18:00 Сдача **очная** на онлайн занятии.\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания.\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "\n",
    "[ML0422, Задание 2] Фамилия Имя.\n",
    "\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст, если явно не указана такая возможность. В противном случае -1 балл\n",
    "<hr\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Здравствуйте, уважаемые студенты! \n",
    "\n",
    "В этом задании мы будем реализовать линейные модели. Необходимо реализовать линейную и логистическую регрессии с L2 регуляризацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Теоретическое введение\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Линейная регрессия решает задачу регрессии и оптимизирует функцию потерь MSE \n",
    "\n",
    "$$L(w) =  \\frac{1}{N}\\left[\\sum_i (y_i - a_i) ^ 2 \\right], $$ где $y_i$ $-$ целевая функция,  $a_i = a(x_i) =  \\langle\\,x_i,w\\rangle ,$ $-$ предсказание алгоритма на объекте $x_i$, $w$ $-$ вектор весов (размерности $D$), $x_i$ $-$ вектор признаков (такой же размерности $D$).\n",
    "\n",
    "Не забываем, что здесь и далее  мы считаем, что в $x_i$ есть тождественный вектор единиц, ему соответствует вес $w_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Логистическая регрессия является линейным классификатором, который оптимизирует так называемый функционал log loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$$L(w) = - \\frac{1}{N}\\left[\\sum_i y_i \\log a_i + ( 1 - y_i) \\log (1 - a_i) \\right],$$\n",
    "где  $y_i  \\in \\{0,1\\}$ $-$ метка класса, $a_i$ $-$ предсказание алгоритма на объекте $x_i$. Модель пытается предсказать апостериорую вероятность объекта принадлежать к классу \"1\":\n",
    "$$ p(y_i = 1 | x_i) = a(x_i) =  \\sigma( \\langle\\,x_i,w\\rangle ),$$\n",
    "$w$ $-$ вектор весов (размерности $D$), $x_i$ $-$ вектор признаков (такой же размерности $D$).\n",
    "\n",
    "Функция $\\sigma(x)$ $-$ нелинейная функция, пероводящее скалярное произведение объекта на веса в число $\\in (0,1)$ (мы же моделируем вероятность все-таки!)\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$$\n",
    "\n",
    "Если внимательно посмотреть на функцию потерь, то можно заметить, что в зависимости от правильного ответа алгоритм штрафуется или функцией $-\\log a_i$, или функцией $-\\log (1 - a_i)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Часто для решения проблем, которые так или иначе связаны с проблемой переобучения, в функционал качества добавляют слагаемое, которое называют ***регуляризацией***. Итоговый функционал для линейной регрессии тогда принимает вид:\n",
    "\n",
    "$$L(w) =  \\frac{1}{N}\\left[\\sum_i (y_i - a_i) ^ 2 \\right] + \\frac{1}{C}R(w) $$\n",
    "\n",
    "\n",
    "Для логистической: \n",
    "$$L(w) = - \\frac{1}{N}\\left[\\sum_i y_i \\log a_i + ( 1 - y_i) \\log (1 - a_i) \\right] +  \\frac{1}{C}R(w)$$\n",
    "\n",
    "Самое понятие регуляризации введено основателем ВМК академиком Тихоновым https://ru.wikipedia.org/wiki/Метод_регуляризации_Тихонова\n",
    "\n",
    "Идейно методика регуляризации заключается в следующем $-$ мы рассматриваем некорректно поставленную задачу (что это такое можно найти в интернете), для того чтобы сузить набор различных вариантов (лучшие из которых будут являться переобучением ) мы вводим дополнительные ограничения на множество искомых решений. На лекции Вы уже рассмотрели два варианта регуляризации.\n",
    "\n",
    "$L1$ регуляризация:\n",
    "$$R(w) = \\sum_{j=1}^{D}|w_j|$$\n",
    "$L2$ регуляризация:\n",
    "$$R(w) =  \\sum_{j=1}^{D}w_j^2$$\n",
    "\n",
    "С их помощью мы ограничиваем модель в  возможности выбора каких угодно весов минимизирующих наш лосс, модель уже не сможет подстроиться под данные как ей угодно. \n",
    "\n",
    "Вам нужно добавить соотвествущую Вашему варианту $L2$ регуляризацию.\n",
    "\n",
    "И так, мы поняли, какую функцию ошибки будем минимизировать, разобрались, как получить предсказания по объекту и обученным весам. Осталось разобраться, как получить оптимальные веса. Для этого нужно выбрать какой-то метод оптимизации.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Градиентный спуск является самым популярным алгоритмом обучения линейных моделей. В этом задании Вам предложат реализовать стохастический градиентный спуск или  мини-батч градиентный спуск (мини-батч на русский язык довольно сложно перевести, многие переводят это как \"пакетный\", но мне не кажется этот перевод удачным). Далее нам потребуется определение **эпохи**.\n",
    "Эпохой в SGD и MB-GD называется один проход по **всем** объектам в обучающей выборки.\n",
    "* В SGD градиент расчитывается по одному случайному объекту. Сам алгоритм выглядит примерно так:\n",
    "        1) Перемешать выборку\n",
    "        2) Посчитать градиент функции потерь на одном объекте (далее один объект тоже будем называть батчем)\n",
    "        3) Сделать шаг спуска\n",
    "        4) Повторять 2) и 3) пока не пройдет максимальное число эпох.\n",
    "* В Mini Batch SGD - по подвыборке объектов. Сам алгоритм выглядит примерно так::\n",
    "        1) Перемешать выборку, выбрать размер мини-батча (от 1 до размера выборки)\n",
    "        2) Почитать градиент функции потерь по мини-батчу (не забыть поделить на  число объектов в мини-батче)\n",
    "        3) Сделать шаг спуска\n",
    "        4) Повторять 2) и 3) пока не пройдет максимальное число эпох.\n",
    "* Для отладки алгоритма реализуйте возможность  вывода средней ошибки на обучении модели по объектам (мини-батчам). После шага градиентного спуска посчитайте значение ошибки на объекте (или мини-батче), а затем усредните, например, по ста шагам. Если обучение проходит корректно, то мы должны увидеть, что каждые 100 шагов функция потерь уменьшается. \n",
    "* Правило останова - максимальное количество эпох\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Теоретические вопросы (2 балла)\n",
    "В этой части Вам будут предложены теоретичские вопросы и задачи по теме. Вы, конечно, можете списать их у своего товарища или найти решение в интернете, но учтите, что они обязательно войдут в теоретический коллоквиум. Лучше разобраться в теме сейчас и успешно ответить на коллоквиуме, чем списать, не разобравшись в материале, и быть терзаемым совестью. \n",
    "\n",
    "\n",
    "Формулы надо оформлять в формате **LaTeX**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Задача 1. Градиент для линейной регрессии.\n",
    "* Выпишите формулу обновления весов для линейной регрессии с L2 регуляризацией для мини-батч градиентого спуска размера $n$:\n",
    "\n",
    "$$ w_{new} = w_{old} - ... $$\n",
    "\n",
    " Отнеситесь к этому пункту максимально серьезно, это Вам нужно будет реализовать в задании.\n",
    " \n",
    "Проанализруйте итоговую формулу градиента - как  интуитивно можно  описать, чему равен градиент?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Ваше решение здесь***\n",
    "$$ w_{new} = w_{old} - \\alpha\\nabla_wQ(w)$$\n",
    "\n",
    "$$\\nabla_wQ(w) = \\frac{2}{n}\\sum_{i=1}^{n}(a_i - y_i)\\sum_{j=1}^{D}x_i{}_j + \\frac{2}{C}\\sum_{j=1}^{D}w_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Задача 2. Градиент для логистической регрессии.\n",
    "* Выпишите формулу обновления весов для логистической регрессии с L2 регуляризацией  для мини-батч градиентого спуска размера $n$:\n",
    "\n",
    "$$ w_{new} = w_{old} - ... $$\n",
    "\n",
    " Отнеситесь к этому пункту максимально серьезно, это Вам нужно будет реализовать в задании.\n",
    " \n",
    "Проанализруйте итоговую формулу градиента - как  интуитивно можно  описать, чему равен градиент? Как соотносится этот градиент с градиентом, возникающий в задаче линейной регрессии?\n",
    "\n",
    "Подсказка: Вам градиент, которой получается если “в лоб” продифференцировать,  надо немного преобразовать.\n",
    "Надо подставить, что $1 - \\sigma(w,x) $ это  $1 - a(x_i)$, а  $-\\sigma(w,x)$ это $0 - a(x_i)$.  Тогда получится свести к одной красивой формуле с линейной регрессией, которую программировать будет намного проще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Ваше решение здесь***\n",
    "$$ w_{new} = w_{old} - \\alpha\\nabla_wQ(w)$$\n",
    "\n",
    "$$a_i = \\sigma(x_i, w)$$\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "$$\\nabla_wQ(w) = \\frac{1}{n}\\sum_{i=1}^{n}(a_i-y_i)\\sum_{j=1}^{D}x_i{}_j + \\frac{2}{C}\\sum_{j=1}^{D}w_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Задача 3. Точное решение линейной регрессии\n",
    "\n",
    "На лекции было показано, что точное решение линейной регрессии имеет вид $w = (X^TX)^{-1}X^TY $. \n",
    "* Покажите, что это действительно является точкой минимума в случае, если матрица X имеет строк не меньше, чем столбцов и имеет полный ранг. Подсказка: посчитайте Гессиан и покажите, что в этом случае он положительно определен. \n",
    "* Выпишите точное решение для модели с $L2$ регуляризацией. Как L2 регуляризация помогает с точным решением где матрица X имеет линейно зависимые признаки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Ваше решение здесь***\n",
    "\n",
    "$$Q(w, X, Y) = \\frac{1}{N}\\sum_{i=1}^{N}(a_i - y_i)^2$$\n",
    "\n",
    "$$Q'_{w_j} = \\frac{2}{N}\\sum_{i=1}^{N}x_i{}_j(a_i - y_i)$$\n",
    "\n",
    "$$Q\"_{w_j}{}_{w_k} = \\frac{2}{N}\\sum_{i=1}^{N}x_i{}_jx_i{}_k = \\frac{2}{N}(x'_j, x'_k)$$\n",
    "\n",
    "$ x'_j, x'_k \\space это \\space j-ый\\spaceи\\space k-ый\\spaceстолбцы\\spaceматрицы\\space X$\n",
    "\n",
    "Гессиан равен матрице Грамма системы векторов, состоящей из столбцов матрицы X.\n",
    "\n",
    "Матрица X имеет полный ранг, а значит столбцы образуют некоторый базис лин. пространства векторов (N, 1).\n",
    "\n",
    "Известно, что матрица Грамма, образованная из линейно независимой системы векторов, положительно определена.\n",
    "\n",
    "Значит, наш гессиан положительно определен.\n",
    "\n",
    "$w = (X^TX + С * I)^{-1}X^TY $, где $I$ - это единичная матрица (D, D)\n",
    "\n",
    "Матрица $X^TX$ неотрицательно определена, значит собственные значения неотрицательны, при сложении с диагональной матрицей собственные значения увеличиваются на C, что обеспечивает положительную определенность матрицы\n",
    "$X^TX + С * I$.\n",
    "Обратная матрица также положительная определена.\n",
    "Все это обеспечивает хорошую обусловленность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Задача 4.  Предсказываем вероятности.\n",
    "\n",
    "Когда говорят о логистической регрессии, произносят фразу, что она \"предсказывает вероятности положительного класса\". Давайте разберемся, что же за этим стоит. Посчитаем математическое ожидание функции потерь и проверим, что предсказание алгоритма, оптимизирующее это мат. ожидание, будет являться вероятностью положительного класса. \n",
    "\n",
    "И так, функция потерь на объекте $x_i$, который имеет метку $y_i \\in \\{0,1\\}$  для предсказания $a(x_i)$ равна:\n",
    "$$L(y_i, b) =-[y_i == 1] \\log a(x_i)  - [y_i == 0] \\log(1 - a(x_i)) $$\n",
    "\n",
    "Где $[]$ означает индикатор $-$ он равен единице, если значение внутри него истинно, иначе он равен нулю. Тогда мат. ожидание при условии конкретного $x_i$  по определение мат. ожидания дискретной случайной величины:\n",
    "$$E(L | x_i) = -p(y_i = 1 |x_i ) \\log a(x_i)  - p(y_i = 0 | x_i) \\log( 1 - a(x_i))$$\n",
    "* Докажите, что значение $a(x_i)$, минимизирующее данное мат. ожидание, в точности равно $p(y_i = 1 |x_i)$, то есть равно вероятности положительного класса.\n",
    "\n",
    "Подсказка: возможно, придется воспользоваться, что  $p(y_i = 1 | x_i) + p(y_i = 0 | x_i) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Ваше решение здесь***\n",
    "\n",
    "Пусть $p = p(y_i = 1 |x_i ), a = a(x_i)$\n",
    "\n",
    "Требуется найти минимум функции f\n",
    "\n",
    "$f(a) = -p\\log(a)-(1 - p)\\log(1 - a)$\n",
    "\n",
    "$f'_a = -\\frac{p}{a} + \\frac{1 - p}{1 - a} = \\frac{a - p}{a(1 - a)} = 0$\n",
    "\n",
    "Значит $p = a$ или $a(x_i) = p(y_i = 1 |x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Задача 5.  Смысл регуляризации.\n",
    "\n",
    "Нужно ли в L1/L2 регуляризации использовать свободный член $w_0$ (который не умножается ни на какой признак)?\n",
    "\n",
    "Подсказка: подумайте, для чего мы вводим $w_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Ваше решение здесь***\n",
    "\n",
    "$w_0$ вводится для описания постоянных параметров.\n",
    "Представляет из себя некое \"начальное состояние\" относительно которого происходят изменения за счет переменных параметров.\n",
    "Это хорошо видно в случае, если параметры никак не влияют на целевую функцию (она константа или колеблется в маленькой окрестности), тогда целесообразнее описать модель через смещение относительно этой константы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  Реализация линейной модели (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Зачем нужны батчи?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как Вы могли заметить из теоретического введения, что в случае SGD, что в случае mini-batch GD,  на каждой итерации обновление весов  происходит только по небольшой части данных (1 пример в случае SGD, batch примеров в случае mini-batch). То есть для каждой итерации нам *** не нужна вся выборка***. Мы можем просто итерироваться по выборке, беря батч нужного размера (далее 1 объект тоже будем называть батчом).\n",
    "\n",
    "Легко заметить, что в этом случае нам не нужно загружать все данные в оперативную память, достаточно просто считать батч с диска, обновить веса, считать диска другой батч и так далее. В целях упрощения домашней работы, прямо с диска  мы считывать не будем, будем работать с обычными numpy array. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Немножко про генераторы в Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Идея считывания данных кусками удачно ложится на так называемые ***генераторы*** из языка Python. В данной работе Вам предлагается не только разобраться с логистической регрессией, но  и познакомиться с таким важным элементом языка.  При желании Вы можете убрать весь код, связанный с генераторами, и реализовать логистическую регрессию и без них, ***штрафоваться это никак не будет***. Главное, чтобы сама модель была реализована правильно, и все пункты были выполнены. \n",
    "\n",
    "Подробнее можно почитать вот тут https://anandology.com/python-practice-book/iterators.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "К генератору стоит относиться просто как к функции, которая порождает не один объект, а целую последовательность объектов. Новое значение из последовательности генерируется с помощью ключевого слова ***yield***. Ниже Вы можете насладиться  генератором чисел Фибоначчи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fib(max_iter=4):\n",
    "    a, b = 0, 1\n",
    "    iter_num = 0\n",
    "    while 1:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        iter_num += 1\n",
    "        if iter_num == max_iter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вот так можно сгенерировать последовательность Фибоначчи. \n",
    "\n",
    "Заметьте, что к генераторам можно применять некоторые стандартные функции из Python, например enumerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "new_generator = fib()\n",
    "for j, fib_val in enumerate(new_generator):\n",
    "    print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Пересоздавая объект, можно сколько угодно раз генерировать заново последовательность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n",
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n",
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 3):\n",
    "    new_generator = fib()\n",
    "    for j, fib_val in enumerate(new_generator):\n",
    "        print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "А вот так уже нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "new_generator = fib()\n",
    "for i in range(0, 3):\n",
    "    for j, fib_val in enumerate(new_generator):\n",
    "        print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Концепция крайне удобная для обучения  моделей $-$ у Вас есть некий источник данных, который Вам выдает их кусками, и Вам совершенно все равно откуда он их берет. Под ним может скрывать как массив в оперативной памяти, как файл на жестком диске, так и SQL база данных. Вы сами данные никуда не сохраняете, оперативную память экономите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Если Вам понравилась идея с генераторами, то Вы можете реализовать свой, используя прототип batch_generator. В нем Вам нужно выдавать батчи признаков и ответов для каждой новой итерации спуска. Если не понравилась идея, то можете реализовывать SGD или mini-batch GD без генераторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def batch_generator(X, y, shuffle=True, batch_size=1):\n",
    "    \"\"\"\n",
    "    Генератор новых батчей для обучения\n",
    "    X          - матрица объекты-признаки\n",
    "    y_batch    - вектор ответов\n",
    "    shuffle    - нужно ли случайно перемешивать выборку\n",
    "    batch_size - размер батча ( 1 это SGD, > 1 mini-batch GD)\n",
    "    Генерирует подвыборку для итерации спуска (X_batch, y_batch)\n",
    "    \"\"\"\n",
    "    amount = len(X)\n",
    "\n",
    "    if shuffle:\n",
    "        united = np.hstack((X, y.reshape(amount, 1)))\n",
    "        random.shuffle(united)\n",
    "        X ,y = united[:, :-1], united[:, -1]\n",
    "\n",
    "    for i in range(0, amount, batch_size):\n",
    "        if amount - i < batch_size:\n",
    "            X_batch = X[i:]\n",
    "            y_batch = y[i:]\n",
    "        else:\n",
    "            X_batch = X[i:i + batch_size]\n",
    "            y_batch = y[i:i + batch_size]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "# Теперь можно сделать генератор по данным ()\n",
    "#  my_batch_generator = batch_generator(X, y, shuffle=True, batch_size=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Вычисляем значение сигмоида.\n",
    "    X - выход линейной модели\n",
    "    \"\"\"\n",
    "    ## Your code Here\n",
    "    try:\n",
    "        return 1.0 / (1.0 + math.exp(-x))\n",
    "    except OverflowError as err:\n",
    "        print(x)\n",
    "        raise err\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class MySGDClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, batch_generator, batch_size=1, shuffle=True,\n",
    "                 C=1, p=2, alpha=0.01, max_epoch=10, model_type='lin_reg',\n",
    "                 epsilon=0.0000001):\n",
    "        \"\"\"\n",
    "        batch_generator -- функция генератор, которой будем создавать батчи\n",
    "        C - коэф. регуляризации\n",
    "        alpha - скорость спуска\n",
    "        max_epoch - максимальное количество эпох\n",
    "        model_type - тим модели, lin_reg или log_reg\n",
    "        \"\"\"\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.p = p\n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.K = 0\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_generator = batch_generator\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.errors_log = {'iter' : [], 'loss' : []}  \n",
    "        self.model_type = model_type\n",
    "        self.weights = None\n",
    "        self.sep = 0.5\n",
    "    \n",
    "    def calc_loss(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем функцию потерь по батчу \n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудьте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        \n",
    "        loss = 0\n",
    "        if self.model_type == 'lin_reg':\n",
    "            sh = X_batch.shape\n",
    "            xw = np.matmul(X_batch, self.weights.reshape(sh[1], 1))\n",
    "            y_minus_xw = y_batch.reshape(sh[0],) - xw.reshape(sh[0],)\n",
    "            loss += np.dot(y_minus_xw, y_minus_xw)\n",
    "        elif self.model_type == 'log_reg':\n",
    "            for x, y in zip(X_batch, y_batch):\n",
    "                some = sigmoid(np.dot(x, self.weights))\n",
    "                loss += (math.log(some) if y == 1 else math.log(1 - some))\n",
    "            loss *= -1\n",
    "        else:\n",
    "            raise ValueError('Wrong model type mode: ' + self.model_type)\n",
    "\n",
    "        loss /= len(X_batch)\n",
    "        reg = 0\n",
    "        for w in self.weights:\n",
    "            reg += w ** 2\n",
    "        reg /= self.C\n",
    "        loss += reg\n",
    "        return loss\n",
    "    \n",
    "    def calc_loss_grad(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем градиент функции потерь по батчу (то что Вы вывели в задании 1)\n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудьте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        \n",
    "        loss_grad = 0\n",
    "        if self.model_type == 'lin_reg':\n",
    "            for x, y in zip(X_batch, y_batch):\n",
    "                loss_grad += (np.dot(x, self.weights) - y) * (1 + np.asarray(x).sum())\n",
    "            loss_grad *= 2\n",
    "        elif self.model_type == 'log_reg':\n",
    "            for x, y in zip(X_batch, y_batch):\n",
    "                some = sigmoid(np.dot(x, self.weights))\n",
    "                loss_grad += (some - y) * (1 + np.asarray(x).sum())\n",
    "        else:\n",
    "            raise ValueError('Wrong model type mode: ' + self.model_type)\n",
    "        loss_grad /= len(X_batch)\n",
    "        \n",
    "        reg = 0\n",
    "        for w in self.weights:\n",
    "            reg += w\n",
    "        reg /= self.C\n",
    "        reg *= 2\n",
    "        loss_grad += reg\n",
    "        return loss_grad\n",
    "    \n",
    "    def update_weights(self, new_grad):\n",
    "        \"\"\"\n",
    "        Обновляем вектор весов\n",
    "        new_grad - градиент по батчу\n",
    "        \"\"\"\n",
    "        self.K += 1\n",
    "        self.weights = self.weights - (self.alpha / (self.K ** self.p)) * new_grad\n",
    "    \n",
    "    def fit(self, X, y, prints=False):\n",
    "        \"\"\"\n",
    "        Обучение модели\n",
    "        X - матрица объекты-признаки\n",
    "        y - вектор ответов\n",
    "        \"\"\"\n",
    "\n",
    "        X = np.array(X)\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Нужно инициализировать случайно веса\n",
    "        self.weights = 2 * np.random.random_sample((X.shape[1],)) - 1\n",
    "        self.K = 0\n",
    "\n",
    "        for n in range(0, self.max_epoch):\n",
    "            mid = 0\n",
    "            num = 0\n",
    "            new_epoch_generator = self.batch_generator(X, y, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "            for batch_num, new_batch in enumerate(new_epoch_generator):\n",
    "                X_batch = new_batch[0]\n",
    "                y_batch = new_batch[1]\n",
    "                batch_grad = self.calc_loss_grad(X_batch, y_batch)\n",
    "                self.update_weights(batch_grad)\n",
    "                # Подумайте в каком месте стоит посчитать ошибку для отладки модели\n",
    "                # До градиентного шага или после\n",
    "                batch_loss = self.calc_loss(X_batch, y_batch)\n",
    "                self.errors_log['iter'].append(batch_num)\n",
    "                self.errors_log['loss'].append(batch_loss)\n",
    "                mid += batch_loss\n",
    "                num += 1\n",
    "            print(n, mid / num) if prints else None\n",
    "\n",
    "        best_score = 0\n",
    "        best_sigma = 0\n",
    "        for pretend in list(np.linspace(0.0, 1.0, 20)):\n",
    "            score = f1_score(y, self.predict_edge(X, pretend))\n",
    "            print(pretend, score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_sigma = pretend\n",
    "        self.sep = best_sigma\n",
    "        return self\n",
    "\n",
    "    def predict_edge(self, X, sigma):\n",
    "        if self.model_type == 'lin_reg':\n",
    "            return np.array([1 if np.dot(x, self.weights) >= sigma else 0 for x in X])\n",
    "        elif self.model_type == 'log_reg':\n",
    "            return np.array([1 if sigmoid(np.dot(x, self.weights)) >= sigma else 0 for x in X])\n",
    "        else:\n",
    "            raise ValueError('Wrong model type mode: ' + self.model_type)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание класса\n",
    "        X - матрица объекты-признаки\n",
    "        Не забудьте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        # Желательно здесь использовать матричные операции между X и весами, например, numpy.dot \n",
    "        return self.predict_edge(X, self.sep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%pycodestyle\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Запустите обе регрессии на синтетических данных. \n",
    "\n",
    "\n",
    "Выведите полученные веса и нарисуйте разделяющую границу между классами (используйте только первых два веса для первых двух признаков X[:,0], X[:,1] для отображения в 2d пространство ).  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def plot_decision_boundary(clf, X):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    w = clf.weights\n",
    "    plt.plot([(0.5 - y_min * w[2]) / w[1], (0.5 - y_max * w[2]) / w[1]], [y_min, y_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.634980988593156\n",
      "WEIGHTS: [-0.24543313 -0.04375886 -1.45030067]\n",
      "0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x1dbbd0de7a0>"
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "C1 = np.array([[0., -0.8], [1.5, 0.8]])\n",
    "C2 = np.array([[1., -0.7], [2., 0.7]])\n",
    "gauss1 = np.dot(np.random.randn(200, 2) + np.array([5, 3]), C1)\n",
    "gauss2 = np.dot(np.random.randn(200, 2) + np.array([1.5, 0]), C2)\n",
    "\n",
    "X = np.vstack([gauss1, gauss2])\n",
    "y = np.r_[np.ones(200), np.zeros(200),]\n",
    "\n",
    "clf = MySGDClassifier(max_epoch=20, batch_generator=batch_generator, batch_size=20, model_type='lin_reg', C=10., alpha=0.1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "print('ACCURACY:', f1_score(y, y_pred))\n",
    "print('WEIGHTS:', clf.weights)\n",
    "\n",
    "plot_decision_boundary(clf, X)\n",
    "\n",
    "print(clf.sep)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее будем анализировать Ваш алгоритм. \n",
    "Для этих заданий используйте датасет ниже."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000, n_features=10, \n",
    "                           n_informative=4, n_redundant=0, \n",
    "                           random_state=123, class_sep=1.0,\n",
    "                           n_clusters_per_class=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Покажите сходимости обеих регрессией на этом датасете: изобразите график  функции потерь, усредненной по $N$ шагам градиентого спуска, для разных `alpha` (размеров шага). Разные `alpha` расположите на одном графике. \n",
    "\n",
    "$N$ можно брать 10, 50, 100 и т.д. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.976913146431623\n",
      "1 1.9769482489063832\n",
      "2 1.9778287899621723\n",
      "3 1.9714300094083923\n",
      "4 1.9718356159154042\n",
      "5 1.9822886936555566\n",
      "6 1.9750130945439066\n",
      "7 1.9848175537997437\n",
      "8 1.9714216804855764\n",
      "9 1.9766565467212371\n",
      "0.0 0.6667555496300247\n",
      "0.05263157894736842 0.6346633932389004\n",
      "0.10526315789473684 0.6068765534382767\n",
      "0.15789473684210525 0.5827307842862103\n",
      "0.21052631578947367 0.5616678613369123\n",
      "0.2631578947368421 0.5411820219417246\n",
      "0.3157894736842105 0.5203376199257497\n",
      "0.3684210526315789 0.5000964401023104\n",
      "0.42105263157894735 0.4802413168410377\n",
      "0.47368421052631576 0.4596534031789315\n",
      "0.5263157894736842 0.4386861381807351\n",
      "0.5789473684210527 0.41663198443655086\n",
      "0.631578947368421 0.3918993990202515\n",
      "0.6842105263157894 0.36704516566392675\n",
      "0.7368421052631579 0.3363431151241535\n",
      "0.7894736842105263 0.30271068201569024\n",
      "0.8421052631578947 0.26099921594838116\n",
      "0.894736842105263 0.2027222869483675\n",
      "0.9473684210526315 0.12137823022709475\n",
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "MySGDClassifier(C=5.0, alpha=0.0005,\n                batch_generator=<function batch_generator at 0x000001DBA0A97E20>,\n                batch_size=50, model_type='log_reg', p=5)"
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your Code Here\n",
    "save = np.array(X)\n",
    "\n",
    "my_clf = MySGDClassifier(p=5, max_epoch=10, batch_generator=batch_generator, batch_size=50, model_type='log_reg', C=5., alpha=0.0005)\n",
    "my_clf.fit(X, y, prints=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5001\n",
      "0.6667555496300247\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "pred = my_clf.predict(X)\n",
    "print(accuracy_score(y, pred))\n",
    "print(f1_score(y, pred))\n",
    "print(my_clf.sep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Что Вы можете сказать про сходимость метода при различных `alpha`? Какое значение стоит выбирать для лучшей сходимости?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Изобразите график среднего значения весов для обеих регрессий в зависимости от коеф. регуляризации С из `np.logspace(3, -3, 10)` "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Your Code Here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Довольны ли Вы, насколько сильно уменьшились Ваши веса? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Боевое применение (4  балла)\n",
    "\n",
    "**Защита данной части возможна только при преодолении в проекте бейзлайна Handmade baseline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте применим модель на итоговом проекте! Датасет сделаем точно таким же образом, как было показано в project_overview.ipynb\n",
    "\n",
    "Применим обе регрессии, подберем для них параметры и сравним качество. Может быть Вы еще одновременно с решением домашней работы подрастете на лидерборде!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title\n",
    "print (len(doc_to_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train_groups.csv')\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train = []\n",
    "X_train = []\n",
    "groups_train = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "        y_train.append(target_id)\n",
    "        groups_train.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j, target_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            all_dist.append(len(words.intersection(words_j)))\n",
    "        X_train.append(sorted(all_dist, reverse=True)[0:15])\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "groups_train = np.array(groups_train)\n",
    "print (X_train.shape, y_train.shape, groups_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Подберите размер батча для обучения. Линейная модель не должна учиться дольше нескольких минут. \n",
    "\n",
    "Не забывайте использовать скейлер!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разбейте данные на обучение и валидацию. Подберите параметры C, alpha, max_epoch, model_type на валидации (Вы же помните, как правильно в этой задаче делать валидацию?)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Подберите порог линейной модели, по достижении которого, Вы будете относить объект к классу 1. Вспомните, какую метрику мы оптимизируем в соревновании.  Как тогда правильно подобрать порог?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "С лучшими параметрами на валидации сделайте предсказание на тестовом множестве, отправьте его на проверку на платформу kaggle. Убедитесь, что Вы смогли побить public score первого бейзлайна."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "** При сдаче домашки Вам необходимо кроме ссылки на ноутбук показать Ваш ник на kaggle, под которым Вы залили решение, которое побило Handmade baseline. **"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Какие аспекты обучения линейных моделей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе.   "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "*** ВАШ ОТЗЫВ ЗДЕСЬ***"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "402px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}